---
title: python综合
author: zhangxin
tags:
  - private
  - python
date: 2023-08-17 14:01:13
categories: python
---

## Python综合

#### python的数据类型

int,str,set,list,dict,tuple,float

**可变类型**:可以进行修改,修改后物理地址不发生改变,内部元素发生变化,外部对象不变

	-  list
	-  set
	-  dict

**不可变类型:**不可以进行修改,修改后变为一个新的对象,物理地址发生改变,内部元素不可修改

id(object) 可以查看对象的 是否发生改变



#### dict的key

字典的key和value是一一对应的,所以key需要满足哈希算法的,可变的数据类型是不可以当key的

字典的查询,删除,添加的平均时间复杂度都是O(1), 相比列表与元组,性能更优.

python3.6之前的是无序字典

	-  字典底层维护了一张哈希表,哈希表中每一个元素存储了,哈希值hash,键key,值value

python3.7含之后是有序的

	- 两张表 一个空表(enteies)存储哈希值hash键key值value, 一个列表(indices)存储位置信息index
 - 取值的顺序:
   - dict([key])
   - Hash_value = hash(key)  计算键的哈希值
   - index = hash_value&(Len(indices)-1)  
   - entey_index = indices[index]   index指向enteies中的位置
   - value = enteies[entey_index]

字典的平均时间复杂度是O(1),因为字典是通过哈希算法来实现的,哈希算法不可避免的问题就是hash冲突,python字典发生哈希冲突时,会向下寻找空余位置,直到找到位置.如果在计算key的hash的值时,如果一直找不到空余位置,则字典的时间复杂度就变成了O(n)了



#### 哈希算法

哈希算法又称摘要算法,作用时对任意输入数据进行计算,得到一个固定长度的输出摘要

哈希算法的特点:

- 相同的输入一定的到相同的输出
- 不同的输入大概率得到不同的输出

哈希算法的目的就是验证原始数据是否被篡改



#### python字典哈希冲突问题

- python字典检查两个值是否相等,是比较两个值的哈希值是否相等

- 具有不同值的对象也有可能hash值一样,比如:hash(5)和hash(5.0) 称为哈希冲突

- 哈希冲突的解决办法:

  - 开放寻址法:
    - 从发生碰撞的单元起,按照一定的顺序,从哈希表中寻找一个空闲单元,存放发生碰撞的元素,这个空闲的单元又称为空白单元,或开放单元
    - 开放寻址法现象成一个找车位的问题,如果当前车位有车了就继续往前走,去找下一个空的停车位
    - 方法1: 线性探测法,顺序查找每一个空位,直到找到空位,每次步长为1
    - 方法2: 二次探查,在表的左右位置根据一定的步长进行跳跃探索,每次步长为n
    - 方法3: 伪随机探测,根据公式生成一个随机数,步长以这个随机数为准进行探测
  - 再哈希法:
    - 就是换个哈希函数继续计算,可能还会造成冲突,多准备几个哈希函数
  - 链地址法:
    - 就是把哈希值相同的值放到同一个链表再挨个查,优点是不同的哈希值不会冲突

  - 公共溢出区:
    - 把所有冲突的放在一个特定的溢出区,去那里找



#### 装饰器

实质上也是一个闭包函数,也是一个嵌套函数

作用:

- 在不改变原函数的情况下,对已有函数进行额外的功能扩展

条件:

- 不修改已有函数的源代码
- 不修改已有函数的调用方式
- 给已有函数增加额外的功能

与闭包的区别:

- 参数有且只有一个,并且是函数类型



#### 闭包

闭包就是能够读取其他函数内部变量的函数

作用:

- 保存外部函数的变量,不会随着外部函数调用而销毁

条件:

- 函数嵌套
- 内部函数必须使用了外部函数的变量或参数
- 外部函数返回内部函数,这个使用了外部函数变量的内部函数称为闭包



#### 函数与方法的区别

- 函数是独立的代码块,用于完成独立的任务
- 方法是类中的函数,用于描述类的行为



#### 对象是什么

- 地址 id()
- 类型 type()
- 值 value()



#### 类的继承顺序

- mro()算法



#### GC垃圾回收

引用计数是python的必需功能,分代回收可选(gc.disable 禁用分代回收),gc.collect()手动触发对象回收

- 引用计数
  - 如果没有变量引用某一对象,这个对象就会被回收,python中的每个变量都是对对象的引用,而不是对象本身
  - 核心概念: 变量是指向一个对象的指针,有n个变量指向一个对象,那么该对象的引用计数则为n,又称该对象有n个引用
  - id(变量名)可以查看变量指向的对象的地址, sys.getrefcount(object) 查看引用计数,但是当调用sys.getrefcount()时会临时增加一次引用
  - 缺点: 循环引用,线程锁定以及额外内存和性能开销,循环引用问题会造成内存泄漏
- 分代回收
  - 专门解决循环引用的问题

​	

引用计数实时作用, 循环引用的回收是定期运行的,垃圾回收器将container对象分为三代,每个新对象都从第一代开始,如果一个对象在一个垃圾回收轮次中幸存下来,它将移至较旧(更高)的一代,较低代的回收效率高于较高代,因为大多数新对象往往会被先销毁,这样分代回收的策略能提高性能并减少垃圾回收带来的暂停时间

每一代都有一个独立的计数器和阈值,计数器存储上次收集以来的对象分配数减去释放数的差值,每次分配新的对象容器对象时,cPython都会检查第0代的计数器是否超过阈值(通过gc.get_count()获得三代对象计数器存储的数值),如果超过阈值,python将触发垃圾回收,



#### python对象的生命周期和方法

__ new __ 创建对象

__ init __ 初始化对象

__ del __ 回收、删除对象



#### GIL锁

GIL全局解释器锁,是一个互斥锁,锁是python解释器的而不是python本身的,防止多线程同时执行python的字节码,防止多线程同时访问python对象.GIL锁用来保护指向当前进程状态的指针.



多个线程同时对一个数据进行增加或减少操作,可能导致内存泄漏(引发数据不一致)



一个对象一把锁带来的问题:

- 死锁: 线程之间相互竞争抢锁的资源
- 反复获取和解释锁导致性能降低



GIL锁规则: 任何python字节码的执行都需要获取解释器锁,这样可以防止死锁,并且带来的性能开销不大,但这实际上使所有受cpu约束的python程序(cpu密集型)都是单线程



线程释放GIL锁的两种情况:

- 遇到IO操作
  - 发送一个http请求等,等待响应
  - 当前执行的线程释放后,不再参与锁的抢夺
- time tick到期
  - time tick规定了线程最长执行时间,超过时间后自动释放GIL锁,间隔大致15毫秒
  - 当前执行的线程释放后(多数是cpu密集型任务),继续参与锁的抢夺



单核cpu下 cpu的利用率很高

多核cpu下由于GIL锁的全局特性,无法发挥多核的特性,GIL锁会使的多线程任务的效率大大降低

GIL降低了多核的效率,保留的目的是线程执行的安全问题



#### python 多进程 多线程 协程

- 并行
  - 同一时间执行多个任务,这里指的是同一时间执行了多个任务中的1类操作,即实际占用CPU运算资源的操作,所以并行意味着会用到多个CPU
  - 只有使用多进程机制处理的任务才属于真正的并行
- 并发
  - 同一时间处理多个任务,这里是处理而不是执行,因为对于并发来说,同一时间在执行1类操作的只有一个任务,其他的任务都在执行2类任务,即等待(基本是硬盘或网络I/O),所以并发不需要用到多个CPU

- 同步
  - 一个函数执行结束等待返回结果后再去执行下一个函数
- 异步
  - 异步的本质就是同一时间处理多个任务,且这多个任务可以交替执行,而协程就是执行异步调用的一种方式
- 阻塞
  - 阻塞调用是指调用结果返回之前,当前线程会被挂起,一直处于等待消息通知,不能够执行其他业务,等待当前函数返回

- 非阻塞
  - 非阻塞调用指在不能立刻返回结果之前也会立即返回,同时该函数不会阻塞当前线程
- 多进程
  - 对于cpu密集型任务,采用更多的计算单元,从而到达在单位时间内进行更多的计算操作
  - 多进程采用python标准库multiprocessing.Pool(process).map(function,iterable),process为使用的进程数,默认是os.cpu_count()的返回值,即cpu数量
  - map会阻塞主程序,如果不需要阻塞主程序可以使用map_async(),参数和map一样,但是它会异步多进程
  - 如果function需要传入多个参数,可以使用starmap(),参数和map一样,区别在于starmap会将iterable中的每一项拆包作为function的输入参数
  - 如果function需要传入多个参数且不希望主进程阻塞,可以使用starmap_async()

- 多线程
  - 同时执行多个不同程序
- 协程
  - 对于I/O密集型任务,只需要使各个等待I/O的实际重叠,就能够加速任务执行,使用多线程或协程即可对I/O密集型的任务进行加速
  - 之所以可以使用多线程对I/O密集型任务进行加速,是因为python程序在进行I/O操作时会释放GIL,因此当某一个线程在等待I/O时,可以转而执行下一个线程
  - asynico是python标准库中使用协程来异步执行程序从而实现并发的库
  - async和await是python3.5引入,asyncio.run()是3.7引入的
  - async def 定义且tonguereturn返回值的函数为协程函数,协程函数的返回对象称为协程对象,是可等待对象的一种
  - 通过async def定义且通过 yield返回值的函数称为协程生成器,可以通过 async for 来进行迭代
  - 能够被await驱动的对象类型称为awaitable即可等待对象.python标准库中定义了特殊方法 __ await __()的对象都是可等待对象;主要有三类:coroutine,Task,Future.  corotine就是协程函数返回的对象;Task为asycio.creat_task(coroutine)的返回对象
  - 不使用await或asynico.run驱动,而是直接调用协程函数,则协程函数会返回一个协程对象
  - 协程的执行过程基本和多线程类似,但是协程之间的切换会更紧凑一些. 协程本质上在用户程序和低层线程之间搭建了一个管道,从而把协程调度的工作委派了事件循环.我们确保代码中没有阻塞的代码,事件循环会处理并发
  - 协程相比多线程的优势是没有线程切换的开销,因为协程都是运行在一个线程上,不存在由于多线程的“竞争机制”导致的同时写变量冲突等问题,因此,在协程中对于共享资源不需要加锁



#### 多线程和多进程的使用场景

1. 多线程 多线程是一种并发编程的方式，它可以在同一个进程中创建多个线程，每个线程都可以独立执行任务。多线程可以共享进程的内存空间，从而可以方便地共享数据和资源。多线程适用于 I/O 密集型任务，例如网络通信、文件读写等，以及需要共享数据和资源的任务。
2. 多进程 多进程是一种并发编程的方式，它可以在操作系统中创建多个进程，每个进程都可以独立执行任务。多进程可以通过进程间通信来共享数据和资源，但是相比于多线程，进程间的通信成本更高。多进程适用于 CPU 密集型任务，例如计算密集型算法、图像处理等，以及需要隔离和保护数据和资源的任务。



#### 什么是竞争条件?

- 竞争条件是指当多个进程或线程同时访问共享资源时,由于执行顺序不确定或不可预测时,导致最终结果的正确性受到破坏的情况,最终结果可能与预期不符,因为进程或线程之间的相互竞争导致了不确定的执行顺序
- 可以加锁避免



#### with与上下文管理器

- 上下文管理器
  - 上下文管理器定义执行with语句时要建立运行上下文,负责执行with语句块上下文中的进入与退出操作
  - __ enter __ 方法在语句执行之前进入运行时上下文
  - __ exit __ 方法在语句执行完成后从运行时上下文退出
  - 实际应用中__ enter __一般用于资源分配,如打开文件,链接数据库,获取线程锁, exit 一般用于资源的释放,如关闭文件,关闭数据库连接,释放线程锁

- 使用with试下一个打开关闭数据库的上下文管理器

```python
class DB(object):

    def __init__(self, host, port, user, pwd, database):
        setting = {
            "host": host,
            "port": port,
            "user": user,
            "password": pwd,
            "database": database,
        }
        # 创建数据库连接
        self.dbconn = pymysql.connect(**setting, local_infile=1)
        # 判断数据库链接是否有效
        while True:
            try:
                self.dbconn.ping()
                break
            except OperationalError:
                self.dbconn.ping(True)
        # 创建字典型游标(返回的数据是字典类型)
        self.dbcur = self.dbconn.cursor(cursor=pymysql.cursors.DictCursor)

    # __enter__() 和 __exit__() 是with关键字调用的必须方法
    # with本质上就是调用对象的enter和exit方法
    def __enter__(self):
        # 返回游标
        return self.dbcur

    def __exit__(self, exc_type, exc_value, exc_trace):
        # 提交事务
        self.dbconn.commit()

        # 关闭游标
        self.dbcur.close()

        # 关闭数据库连接
        self.dbconn.close()
```



#### Rabbitmq和Kafka的区别

 rabbitmq

- 消息确认：rabbitmq采用ack机制，确保消息到达消费者。消费者接收并处理消息后需要手动发送ack确认消息已经完成处理
- 消息持久化：rabbitmq可以将消息存储到硬盘上，以便在服务器故障时恢复丢失的数据
- 集群管理：rabbitmq提供了一个可靠的集群管理机制，包括主备模式，故障转移等方式来确保高可用性
- 缺点：rabbitmq的处理数据较慢，因为它依赖磁盘I/O

kafka

- 消息确认：kafka使用分布式提交日志机制，消费者接收到消息后会自动提交确认标记（offset），不需要手动确认
- 消息持久化：kafka将所有消息都存储在磁盘上，因此可以支持大量的消息，并且具有更好的读写性能
- 集群管理：kafka的分布式消息传输设计非常出色，可以轻松扩展以处理海量数据，同时支持动态扩容。
- 缺点：kafka在多点写入时（producer端）性能不如rabblitmq

综上所述，rabbitmq在可靠性和管理方面表现更好，而kafka则具有更好的性能和扩展性。因此，选择哪个系统需要根据具体的业务需求来决定。



#### 传输很长的数据时如何保证数据完整的传输到指定地方

- TCP协议：tcp协议提供可靠的数据传输保证，它会自动进行数据分段、校验和等操作，并发送确认消息来确保数据的可靠性传输，因此，在数据量大且需要保证可靠性的情况下，可以使用tcp协议来进行数据传输
- HTTP分块传输编码：http分块传输编码是一种将数据分成多个块进行传输的方式，每个块都有一个长度标识符和内容，在接收端需要将所有的块合并成一个完整的数据，通过这种方式可以避免一次性传输过大的数据导致连接中断的问题
- 文件压缩：将要传输的数据进行压缩处理，可以减少数据传输的大小，降低数据传输的时间和带宽消耗，并且能提高数据传输的安全性
- 数据摘要算法：在数据传输开始前对要纯属的数据进行摘要计算（如MD5或者SHA），然后计算出来的结果与要传输的数据一起传输。在接收端，再重新计算一次数据摘要，将计算出来的的结果与传输的摘要进行对比，如果一致所用数据完整
- 保证分段数据的顺序
  - tcp协议是一种基于流的协议，会按照发送顺序保证数据的接收顺序，因此，在需要保证数据顺序的情况下，可以使用TCP协议进行传输
  - 消息队列可以保证消息的顺序性和可靠性，适合处理高并发。分布式系统等场景，在消息队列中，每个生产者发送的消息都会被放入队列中，并按照发送顺序进行排序，消费者从队列中取出消息时，会按照发送顺序进行消费
  - 在传输过程中，可以给每个数据包添加一个唯一的序号，然后在接收端根据序号进行排序，从而保证数据的顺序性



#### 布隆过滤器的原理和使用场景

https://juejin.cn/post/7036221560117526541

布隆过滤器是一种快速，高效的数据结构，用于判断一个元素是否存在于一个集合中。其基本原理是将每个元素通过多个相互独立的哈希函数映射成位数组中的多个位置，并将这些位置标记成1。在判断一个元素是否存在，我们只需要检查该元素对应的各个位置是否都被标记为1即可。

布隆过滤器的优点在于空间和时间效率非常高，它可以使用极少的内存来存储海量的数据，并且在插入和查询操作中具有O(k)的时间复杂度，其中K是哈希函数的个数。此外，布隆过滤器还支持动态添加和删除元素，但是删除操作可能会导致误判率的上升。

应用场景：

- 网络爬虫：在爬取网页时，可以使用布隆过滤器来避免重复抓取同一个页面
- 缓存系统：在缓存系统中，我们可以使用布隆过滤器来判断一个请求是否需要从数据库中查询，以提高缓存命中率
- 防止DDOS攻击：在网路安全领域中，布隆过滤器可以用于快速判断一个IP地址是否在黑名单中，以防止DDos攻击等恶意行为
- 数据库查询优化：在数据库查询中，布隆过滤器可以用于排除不存在的记录，从而提高查询效率



#### python抽象类和接口类的区别

- 抽象类
  - 抽象类是不能被实例化的类,它定义了一组方法的名称和参数,但没有具体的实现,子类需要继承这个抽象类,并且必须实现其中定义的所有方法,否则子类也会被认为是抽象类,抽象类通常用于定于一些公共的接口和行为,让子类去实现具体功能.在python中,可以使用abc模块来定义抽象类
- 接口类
  - 接口类也同样定义了一组的名称和参数,但是其特点是所有方法都是空的,没有任何实现.通过继承接口类并实现其中定义的方法,可以达到实现某种特定的功能的目的.在python中,并没有专门的接口类语法,但是可以使用抽象类来实现接口类的功能.

- 区别
  - 抽象类中可以包含非抽象方法(即有实现的方法),而接口类中只包含没有实现的方法
  - 抽象类可以维护一个状态,而接口类则不可以
  - 子类可以使用多继承方式同时继承多个抽象类,但是接口类不支持多继承.

总之,抽象类和接口类都是定义一组方法的规范,它们的区别在于抽象类可以包含有实现的方法,而接口类只包含没有实现的方法.根据具体的需求和设计,选择使用哪种方式来定义抽象规范



#### 元类

- type通常用来判断对象的类型,它最大的用涂是用来动态创建类,当python扫描到class语法的时候,就会调用type函数来创建类

- type如何创建类

  type需要接收三个参数

  - 类的名称,不指定也要传入空字符串

  - 父类的名称,需要tuple的形式传入,没有也需要传入空的tuple,默认继承object

  - 绑定方法或者属性,用dict的形式传入

    ```python
    # 准备一个基类
    class BaseClass:
      def talk(self):
        print("我是人类")
        
    # 准备一个方法
    def say(self):
      print("hello")
      
    # 使用type创建User类
    User = type(“user”,(BaseClass,),{"name":"user": "say":say})
    ```

- 理解什么是元类

  - 元类是创建类的模版
  - type是python是在背后所有创建类的元类,object也是由type创建的,type也是type创建的
  - 一个实例的类型是类,一个类的类型是元类,一个元类的类型是type

#### 分布式锁

- 分布式锁是一种分布式系统中的并发控制，它可以确保在分布式环境中只有一个进程或线程能够访问共享资源，分布式锁通常基于某种可靠的存储系统（如redis）实现，在不同进程或服务器时间协调并管理共享锁
- 分布式锁实现方式通常有两种：基于数据库和基于缓存。基于数据库的实现方式需要使用关系型数据库的行级锁或者悲观锁控制并发访问，但是这种方式由于需要频繁的对数据库进行访问，会给数据库带来较大的性能损耗。而基于缓存的实现方式则需要使用缓存系统的原子加锁操作来实现分布式锁，这种方式相比于基于数据库的方式更加轻量级，但需要注意避免缓存雪崩和缓存穿透的问题。
- 分布式锁在分布式系统中非常重要，它可以解决多个进程或节点之间对共享资源的竞争访问问题，避免了数据不一致和脏读等问题的出现，但是，分布式锁的实现需要注意避免死锁，过期时间的设置以及锁的粒度问题，否则会影响分布式系统的性能和可用性。

###  

## Mysql

https://github.com/caokegege/Interview/blob/master/db/%E6%9C%80%E5%85%A8MySQL%E9%9D%A2%E8%AF%9560%E9%A2%98%E5%92%8C%E7%AD%94%E6%A1%88.md

https://zhuanlan.zhihu.com/p/164511591



#### 数据库同步策略

- 异步复制(mysql默认的同步方式)
  - 在master为slave开通账号密码,ip授权之后,slave可以从master进行数据同步,主要依赖的是master的binlog日志
  - slave会启动两个线程,IO Thread和SQL Thread
  - IO Thread负责从master拉取binlog日志,并写入ralay中继日志
  - SQL Thread负责将relay中继日志中的变更进行更新重放,更新数据来达到跟master保持数据一致的目的
  - 过程中.slave通过IO线程拉取binlog日志,master无需关注是否有slave需要同步,整个复制过程都是异步完成的
  - 优势: 性能好
  - 缺点: 安全性比较差
  - 在某一刻主从之间的数据差异可能比较大,主机挂掉之后从新接管,可能会丢失一部分数据

- 半同步复制
  - master更新操作写入binlog之后会主动通知slave,slave接收到之后写入ralay log即可应答,master只要收到至少一个ack应答,则会提交事物
  - 可以发现,相比较与异步复制,半同步负责需要依赖至少一个slave将binlog写入relay log,在性能上有所降低,但是可以保证至少有一个从库跟master的数据是一致的,数据的安全性提高
  - 对于数据一致性要求高的场景,可以采用半同步复制的同步策略,比如主库挂掉时,准备接管的那一个从库,对数据的一致性要求比较高
  - 优点: 数据的安全性好
  - 缺点: 性能比异步复制稍低

- 全同步复制
  - 全同步复制必须收到所有从库的ack,才会提交事物
  - 从库的事务提交依赖于后面所有的从库,这样一来性能就会明显下降
  - 优点: 数据一致性最好
  - 缺点: 性能也是最差的



#### mysql innodb的四大日志

- **重做日志（Redo Log）：** 重做日志是 InnoDB 存储引擎中最重要的日志之一。它记录了所有已经提交的事务所做的修改，包括数据的插入、更新和删除操作。这些记录可以在数据库发生崩溃时被用来重新应用，从而恢复到最近一次提交的状态。

- **撤销日志（Undo Log）：** 撤销日志记录了事务中所做的修改的反向操作，用于回滚事务或者恢复到事务未提交之前的状态。它保证了在事务回滚或崩溃恢复时，数据的一致性。

- **数据字典日志（Data Dictionary Log）：** 数据字典日志记录了数据字典中的变更操作，如表结构的修改、创建、删除等。这些变更在 InnoDB 数据字典中的表中存储，确保数据结构的一致性和持久性。

- **二进制日志（Binary Log）：** 二进制日志是 MySQL 的服务器层生成的，而不是 InnoDB 存储引擎专用的。它记录了所有影响数据变更的 SQL 语句，包括 DDL（数据定义语言）和 DML（数据操作语言）语句。这些日志可以用于数据复制和恢复。



#### 数据库的几种锁

- 表级锁:开销小,加锁快;不会出现死锁;锁定颗粒度大,发生锁冲突的概率最高,并发度最低

- 行级锁:开销大,加锁慢;会出现死锁;锁定颗粒度最小,发生锁冲突的概率最低,并发度最高

- 页面锁:开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定粒度界于表锁和行锁之间,并发度一般



#### mvcc

- 是一种基于多版本的并发控制协议，只有在innoDB引擎下存在，mvcc是为了实现事务的隔离性，通过版本号，避免同一数据在不同的事务间的竞争，可以当成多版本的乐观锁，这种乐观锁只有在事务级别是提交读和可重复读中有效。mvcc最大的好处就是，读不加锁，读写不冲突。在读多写少的系统中，读写不冲突极大的提高了系统的并发性

![image-20230829112526049](https://raw.githubusercontent.com/zxinyolo/images/main/202308291125111.png)

#### 最左前匹配原则

MySQL 的最左前缀匹配原则与复合索引有关。它是指在使用复合索引进行查询时，索引的最左边的一列是最重要的，后续列只能在前一列的基础上进行进一步筛选。这个原则非常重要，因为它影响着索引的使用效率和查询性能。

具体来说，最左前缀匹配原则有以下几个关键点：

1. **最左列的匹配：** 在一个复合索引中，只有最左边的列在查询中被使用，索引才能有效地优化查询。如果最左边的列没有被使用，那么索引将无法被利用。
2. **左前缀顺序：** 如果查询中涉及到多个列，那么查询的列必须按照索引列的顺序，从最左边的列开始，依次使用。这就是所谓的左前缀顺序。
3. **跳过列：** 当查询涉及到索引的多列时，如果跳过了前面的列直接使用后面的列，索引的效率会降低。例如，如果复合索引是 (col1, col2, col3)，在查询中只使用了 col3，那么索引只能在 col3 上进行搜索，无法有效地利用 col1 和 col2。

这个原则的目的是最大程度地发挥复合索引的优势，减少数据的扫描和过滤，从而提高查询性能。当你设计表结构和创建索引时，要根据实际查询场景，遵循最左前缀匹配原则来选择合适的索引列和顺序，以优化查询性能。



#### 雪花算法的底层原理及优缺点

适合全局唯一且有序的场景

雪花算法是一种用于生成唯一id的算法，底层原理是在分布式系统中使用一个单独的节点来生成全局唯一id

雪花算法的id号由64位二进制数组成，其中包含5个部分

- 时间戳（占用41位）：记录当前时间戳，精确到毫秒级别。
- 工作机器ID（占用12位）：记录工作机器id，可以部署1024个节点
- 序列号（占用12位）：序列号表示当前毫秒类生成的ID序号，从0开始自增，最多可以生成4096个序号
- 数据中心ID（预留1位）：未来可能会使用的数据中心的ID来扩展机器数量
- 符号位（占用1位）：符号位始终为0，保证ID号始终为正整数

优点是能够快速生成全局唯一的ID号，且不需要依赖第三方库或者服务，另外，雪花算法生成的ID是趋势递增的，有利于数据库索引的优化。

缺点是由于依赖单独的节点来生成ID号，因此存在单点故障的风险，其次如果系统的时钟发生回退，就会导致ID号重复或者生成失败，因此需要对时钟进行同步和监控，最后，雪花算法生成的ID号是连续的，可能会暴漏一些敏感信息（如业务量、时间等），如果需要保护隐私，需要使用加密算法或者其他方式处理



#### uuid当数据库主键的优缺点

适合全局唯一且不需要按顺序排列的场景

- 优点
  - 全局唯一，无论在哪个系统生成，都可以保证全局唯一性
  - 不依赖数据库：uuid不需要依赖数据库就可以生成
  - 隐藏真实业务数据：可以隐藏数据的ID，保护数据的安全性
  - 方便分布式系统：避免ID号相同

- 缺点
  - uuid随机生成的导致数据库索引效率低，查询速度慢
  - 长度大，uuid通常是36位数字的字符串表示，占用更多的存储空间



#### mysql的执行流程是什么

- 连接器：登录校验，权限校验
- 缓存：查看是否命中缓存（之前执行过的sql语句，查询的数据库等信息会做哈希放在一个引用表，查询结果以key-value的方式保存，下次如果hash一样直接返回结果）
- 分析器：根据各个sql的关键字进行解析，生成对应的解析树，根据语法规则对sql进行语法分析及校验，解析成mysql可执行的语句
- 优化器：msyql会生成一条最优的执行计划
- 执行器：执行计划
- 存储引擎：返回数据



#### mysql索引下推(ICP)

ICP(index condition pushdown) 是在mysql5.6上推出的查询优化策略,把本来由server层做的索引条件检查下推给存储引擎来做,以降低回表和访问存储引擎的次数,提高查询效率

查询过程:

- 读取索引记录(不是完整的行记录)
- 判断where条件部分能否用索引中的列来做检查,条件不满足,则处理下一条索引记录
- 条件满足,使用索引中的主键去定位并读取完整的行记录(就是所谓的回表)
- 存储引擎把记录交给server层,server层检测该记录是否满足where条件的其余部分

Tips: 索引下推的目的是为了减少回表次数,也就是要减少IO操作.对于innodb的聚簇索引来说,完整的行记录已经加到缓存区了,索引下推也就没有什么意义了



#### 聚簇索引和非聚簇索引的区别

聚簇索引是堆磁盘上实际数据重新组织以按指定的一个或多个列的值排序的算法

特点是存储数据的顺序和索引顺序一致,一般情况下主键会默认创建聚簇索引,且一张表只允许存在一个聚簇索引(理由: 数据一旦存储,顺序只能有一种)



聚簇索引  的叶子节点就是数据节点

非聚簇索引  的叶子节点仍然是索引索引文件,只是这个索引文件包含指向对应数据块的指针



## Redis

https://juejin.cn/post/6844903982066827277

https://xiaolincoding.com/redis/base/redis_interview.html

#### 特点

**Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的。**

采用单线程模式处理请求

- 采用了非阻塞的异步事件处理机制
- 缓存数据都是内存操作IO时间不会太长,单线程可以避免线程上下文切换产生的代价

redis支持持久化,所以它不仅仅可以用作缓存,也可以用作nosql数据库

除了key-value之外,还支持多种数据格式:list,set,zset,hash,string

提供主从同步机制,以及Cluster集群部署能力,能够提供高可用服务



#### Redis是单线程吗?

我们常说的redis单线程指的是:接收客户端请求-> 解析请求-> 进行数据读写等操作-> 返回客户端发生数据,这个过程是由一个线程(主线程)完成的

但是redis程序并不是单线程的,redis启动的时候会启动一个后台线程(BIO):

- redis在2.6版本是会启动两个后台线程,一个用于处理关闭文件,一个用于AOF刷盘的
- Redis 在 4.0 版本之后，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。

之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。

后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。

![img](https://raw.githubusercontent.com/zxinyolo/images/main/202308281532478.png)

关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：

- BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；
- BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，
- BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；



#### Redis单线程模式

Redis 6.0 版本之前的单线模式如下图：

![img](https://raw.githubusercontent.com/zxinyolo/images/main/202308281540584.png)

图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。Redis 初始化的时候，会做下面这几年事情：

- 首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 一个服务端 socket
- 然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；
- 然后，将调用 epoll_crt() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。

初始化完后，主线程就进入到一个事件循环函数，主要会做以下事情：

首先，先调用处理发送队列函数，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发生完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。

接着，调用 epoll_wait 函数等待事件的到来:

- 如果是连接事件到来，则会调用连接事件处理函数，该函数会做这些事情：调用 accpet 获取已连接的 socket ->  调用 epoll_ctr 将已连接的 socket 加入到 epoll -> 注册「读事件」处理函数；
- 如果是读事件到来，则会调用读事件处理函数，该函数会做这些事情：调用 read 获取客户端发送的数据 -> 解析命令 -> 处理命令 -> 将客户端对象添加到发送队列 -> 将执行结果写到发送缓存区等待发送；
- 如果是写事件到来，则会调用写事件处理函数，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发生完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。

以上就是 Redis 单线模式的工作方式。



#### Redis 采用单线程为什么还这么快?

- Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。

所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。但是对于读写命令，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。

Redis 官方表示，Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上。

Redis 6.0 版本支持的 I/O  多线程特性，默认是 I/O 多线程只处理写操作（write client socket），并不会以多线程的方式处理读操作（read client socket）。

#### 数据格式

- string 字符串
  - string类型时redis中最使用的类型,内部的实现是通过SDS(Simple Dynamic String)来存储的.SDS类似java中的ArrayList,可以通过预分配冗余空间的方式来减少内存的频繁分配
  - 这是最简单的类型,就是普通的set和get,做简单的K-V缓存
  - 应用场景: 
    - 缓存功能:
      - string字符串是最常用的数据类型,不仅仅是redis,各个语言多是最基本类希,因此,利用redis作为缓存,配合其它数据作为存储层,利用redis支持高并发的特点,可以大大加快系统的读写速度,以及降低后端数据库的压力
    - 计数器:
      - 许多系统都会使用redis作为系统的实时计数器,可以快速实现计数和查询的功能,而且最终的数据结果可以按照特定的时间落地到数据库或者其他存储介质中进行永久保存
    - 共享用户session
      - 用户重新刷新一次界面,可能需要访问一下数据进行重新登录,或者访问页面缓存Cookie,但是可以利用redis将用户的session集中管理,在这种模式只需要保证Redis的高可用,每次用户Session的更新和获取都可以快速完成,大大提升效率
- Hash
  - 这个类似Map的一种结构,这个一般就是可以将结构化的数据比如一个对象(前提是这个对象没有嵌套其他对象)给缓存在redis里,然后每次读写缓存的时候,可以就操作Hash里的某个字段,但是这个的场景其实还是单一了一些,因为现在很多对象都是比较复杂的,比如你的商品对象可能里面就包含了很多属性,其中也有对象

- List 有序列表
  - 可以通过list存储一些列表的数据结构,类似粉丝列表,文章的评论之类的东西
  - 可以通过Lrange命令,读取某个闭区间内的元素,可以基于List实现分页查询,基于redis实现简单的高性能分页,可以做类似微博那种下拉不断分页的东西,性能高
  - 可以搞个简单的消息队列,从list头添加,从list尾获取
  - 消息队列
    - redis的链表结构,可以轻松实现阻塞队列,可以使用左进右出的命令组成来完成队列的设计,比如数据的生产者可以通过Lpush命令从左边插入数据,多个数据消费者,可以使用BRpop命令阻塞的“抢”列表尾部的数据
    - 文章列表或者数据分页展示的应用
- set 无序集合
  - 可以对一些数据进行快速的全局去重(JVM内存里的HashSet).某个系统部署在多个机器上就可以使用redis进行全局set去重
  - 可以基于set做交集(两个人的好友列表合集-->共同好友),并集,差集
- zset 有序集合
  - 是排序的set,去重但可以排序,写入的时候给一个分数,自动根据分数排序
  - 排行榜 带权重的队列,让更重要的任务优先执行

- 高级用法:
  - Bitmap
    - 位图是支持bit位来存储信息,可以用来实现布隆过滤器
  - HyperLog
    - 供不精确的去重计数功能,比较适合做大规模数据的去重统计,例如统计UV
  - Geospatial
    - 可以用来保存地理位置,并作位置距离计算或者根据半径计算位置等
  - pub/sub
    - 订阅发布功能,可以用作简单的消息队列
  - pipeline
    - 可以批量执行一组指令,一次性返回全部结果,可以减少频繁的请求应答
  - lua
    - redis支持提交lua脚本执行一系列的功能
    - 利用它的原子性可以做秒杀场景
- 事务
  - redis提供的不是严格的事务,redis只保证串行执行命令,并且能保存全部执行,但是执行命令失败时并不会回滚,而是会继续执行下去



#### 持久化

- RDB 快照方式(redis默认的备份方式)

  - 把内存中的数据集以快照形式写入磁盘,实际操作时通过fork子进程执行,采用二进制压缩存储,把整个redis的数据保存在单一文件中,比较适合用来做容灾,冷备
  - 周期性的持久化
  - RDB对redis的性能影响小,因为是fork子进程去做持久化,数据恢复的数据比AOF快
  - 缺点:
    - 快照保存完成之前如果宕机,这段时间的数据将会丢失,另外保存快照时坑可能导致服务器短时间不可用
    - 默认五分钟甚至更久才回生成一次,数据完整性比AOF差

- AOF

  - 以文本日志的形式记录redis处理的每一个写入或删除操作
  - 对日志的写入操作使用的追加模式,有灵活的同步策略,支持每秒同步,每次修改同步和不同步append-only模式没有任何磁盘寻址的开销,所以快,像mysql中的binlog
  - 适合做热备
  - 一秒一次通过一个后台的线程fsync操作,那最多丢一秒的数据
  - 通过一个叫非常可读的方式记录的,这样的特性就适合做灾难性数据误删的紧急恢复了(通过flushall清空了所有数据,只要这个时候后台重写还没有发生,立马拷贝一份AOF日志文件,把最后一条flushall命令删除就可以了)
  - 缺点:
    - 相同规模的数据集,AOF文件要大于RDB文件,AOF在运行效率上往往慢于RDB

  两种机制都开启的时候,redis在重启的时候会默认使用AOF去重新构建数据,因为AOF的数据是比RDB更完整的


#### redis过期删除策略

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间

- 惰性删除
  - 不主动删除键,每当数据库访问数据时,都去检查键是否过期,如果过期就去删除这个键
  - 优点:  很少使用使用系统资源,对cpu友好
  - 缺点: 造成内存占用,浪费内存空间
- 定期删除
  - 每隔一段时间(随机)从数据库中去部分key进行检查,如果key过期就进行删除.从过期字典中随机抽取一定数量的key(可配置),如果过期key占比大于随机抽取的key的25%,就重复定期删除过程,为了房子循环过度,整个定期删设置有时间上限,默认20ms
  - 优点: 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用
  - 缺点: 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放
- 以上两种策略配合使用
  - 合理使用 CPU 时间和避免内存浪费之间取得平衡
- redis持久化对过期key的处理
  - RDB模式: 在生成rdb文件时, 主节点不会保存过期key,从节点会,但是主从同步的时候,从节点的数据会被清空,所以不会对服务器造成影响
  - AOF模式: 会保留过期键,但是当删除过期key的时候,AOF日志中会有删除记录,当重写阶段会对过期key进行检查,已过期的key不会重写到AOF文件中,因此不会对AOF重写造成影响
- redis主从复制对过期key的处理
  - 从库不会对过期key进行过期扫描,从库处理过期key是被动的,当主节点删除过期的key的时候会在AOF文件中增加一条del命令,同步到所有从库,从库根据del指令进行删除

#### redis内存淘汰机制

- 不进行数据淘汰策略
  - 当运行内存操作设置的最大内存,不淘汰任何数据,不再提供任何服务,直接返回错误
- 进行数据淘汰策略
  - 设置了过期时间
    - **volatile-random**：随机淘汰设置了过期时间的任意键值；
    - **volatile-ttl**：优先淘汰更早过期的键值。
    - **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
    - **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；
  - 没设置过期时间
    - **allkeys-random**：随机淘汰任意键值;
    - **allkeys-lru**：淘汰整个键值中最久未使用的键值；
    - **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

#### 高可用

​	支持主从同步,提供Cluster集群部署模式,通过sentinel哨兵来监控redis主服务器的状态.当主挂掉时,在从节点中根据一定策略选出新主,并调整其他从slaveof到新主

策略

​	slave的priority设置的越低,优先级越高

​	同等情况下,slave复制的数据越多优先级越高

​	相同条件下runid越小越容易被选中

在redis集群中,sentinel也会进行多实例部署,sentinel之间通过Raft协议来保证自身的高可用

Redis Cluster使用分片机制,在内部分为16384个slot插槽,分布在所有master节点上,每个master节点负责一部分slot.数据操作时按key做CRC16来计算在哪个slot,由哪个master进行处理.数据的冗余是通过slave节点来保障



#### 哨兵

哨兵必须用三个实例去保证自己的健壮性,哨兵 + 主从 并不能保证数据不丢失,但是可以保证集群的高可用

两个哨兵

​	M1   R1

​	S1    S2

​	master宕机了s1和s2两个哨兵只要有一个认为你宕机了就切换了,并且会举出一个哨兵去执行故障,但是这个时候也需要大多数哨兵都是运行的.问题M1宕机了,S1没挂那其实是OK的,但是整个机器挂了呢,哨兵就只剩下S2了,没有哨兵去允许故障转移了,虽然另外一个机器上还有R1,但是故障转移就是不执行

​	M1   S1

R2-S2    R3-S3

​	M1挂了,S2 和 S3 举一个出来执行故障转移

哨兵组件的主要功能:

​	集群监控:负责监控redis master 和 slave 进程是否正常工作

​	消息通知:如果某个Redis实例有故障,那么哨兵负责发送消息作为报警通知给管理员

​	故障转移:如果master node 挂掉了,会自动转移到 slave node上

​	配置中心:如果故障转移发生了,通知client客户端新的master地址	



#### 主从

单机QPS是有上限的,而且redis的特性就是必须支撑读高并发的

master机器写,数据同步给其他slave机器,slave拿去读

扩容的时候还可以轻松实现水平扩容

#### reids的集群模式

https://www.cnblogs.com/yidengjiagou/p/17345831.html

Redis集群是一种通过将多个Redis节点连接在一起以实现高可用性、数据分片和负载均衡的技术。它允许Redis在不同节点上同时提供服务，提高整体性能和可靠性。根据搭建的方式和集群的特性，Redis集群主要有三种模式：主从复制模式（Master-Slave）、哨兵模式（Sentinel）和Cluster模式。

- **redis集群的优势和作用**
  - **高可用性**: redis集群的某个节点发生故障的时候,自动进行故障转移,保证服务持续可用
  - **负载均衡**: resdis可以把来自服务器的请求分发到不同节点,有效的分摊各节点的压力,提高系统的整体性能
  - **容灾恢复**: 通过主从复制和哨兵模式,redis集群在主节点发生故障时,快速切换到从节点,实现业务的无缝切换
  - **数据分片**: 在Cluster模式下，Redis集群可以将数据分散在不同的节点上，从而突破单节点内存限制，实现更大规模的数据存储。
  - **易于拓展**: Redis集群可以根据业务需求和系统负载，动态地添加或移除节点，实现水平扩展。

- **主从复制(Master-Slave)**

  - **原理**: 通过主节点的数据复制到其他从节点,来达到数据的备份,主节点负责写,从节点负责读,实现读写分离,提高系统性能
  - **优点**: 
    - 配置简单,易于实现
    - 实现数据冗余,提高数据可靠性
    - 读写分离提高系统性能

  - **缺点**: 
    - 主节点故障时需要手动切换到从节点,故障恢复时间长
    - 主节点负责所有写的操作,存在性能瓶颈
    - 无法实现数据分片,依赖单节点内存限制

- **哨兵模式（Sentinel)**

  - **原理**: 哨兵模式是主从复制的基础上加上哨兵节点,哨兵节点的作用是监控主节点和从节点的运行状态,如果主节点发生故障,哨兵节点会从从节点中选举出一个新的主节点,并通知其他的从节点和客户端,实现故障转移
  - **优点**:
    - 自动故障转移,提高系统的可用性
    - 具有主从复制的所有优点
  - **缺点**:
    - 配置复杂难管理
    - 无法实现分片,依赖单节点内存限制

- **Cluster模式(克拉斯特)**

  - **原理**: cluster模式是redis集群中的一种高级模式,通过数据分片和分布式存储实现了负载均衡和高可用性,将所有的键值对分布在各个节点上,每个节点负责一部分数据,称之为槽位,通过对数据的切片,cluster模式可以突破单节点内存的限制,实现存储更大规模的数据
  - **优点**: 
    - 数据分片实现更大规模的数据存储
    - 负载均衡,提高系统性能
    - 自动故障转移,提高高可用性
  - **缺点**:
    - 配置和管理复杂
    - 一些复杂的多键操作可能受到限制



#### 失效机制

redis的key可以设置过期时间,过期后redis采用主动和被动结合的失效机制,一个是和Memcahe一样在访问时触发被动删除,另一种是定期的主动删除

定期 + 惰性 + 内存淘汰



#### 缓存更新方式

缓存的数据在数据源发生变更时需要对缓存进行更新,数据源可能是DB,也可能是远程服务.更新的方式可以是主动更新.数据源是DB时,可以在更新完DB后就直接更新缓存

当数据源是远程服务时,可能无法及时主动感知数据变更,这种情况下一般会选择对缓存数据设置失效期,也就是数据不一致的最大容忍时间

这种场景下,可以选择失效更新,key不存在或失效时先请求数据源获取最新数据,然后再次缓存,并更新失效期

​	问题

​		如果依赖的远程服务在更新时出现异常,则会导致数据不可用

​	办法

​		异步更新,就是当失效时先不清除数据,继续使用旧的数据,然后由异步线程去执行更新任务.这样就避免了失效瞬间的空窗期

​		纯异步更新,定时对数据进行分批更新



#### 数据不一致

只要使用缓存就要考虑如何面对这个问题

缓存不一致的原因:  一般是主动更新失败,例如更新DB后,更新redis因为网络原因请求超时,或者异步更新失败

解决办法:	如果服务对耗时不是特别敏感可以增加重试;如果服务对耗时敏感可以通过异步补偿任务来处理失败的更新,或者短期的数据不一致不会影响业务,那么只要下次更新时可以成功,能保证最终一致性就可以



#### 缓存穿透

原因

​	外部的恶意攻击,例如对用户信息进行了缓存,但恶意攻击者使用不存在的用户id频繁请求接口,导致查询缓存不命中,然后穿透DB查询依然不命中.这时候会有大量请求穿透缓存访问到DB

办法

​	对不存在的用户,在缓存中保存一个空对象进行标记,防止相同ID再次访问DB.不过有时这个方法并不能很好解决问题,可能导致缓存中存储大量无用数据

​	使用BloomFilter过滤器,BloomFilter的特点是存在性检测,如果BloomFilter中不存在,那么数据一定不存在;如果BloomFilter中存在,实际数据也有可能不会存在,非常适合解决这类问题



#### 缓存击穿

原因

​	某个热点数据失效时,大量针对这个数据的请求会穿透到数据源

办法

​	可以使用互斥锁更新,保证同一个进程中针对同一个数据不会并发请求到DB,减小DB压力

​	使用随机退避方式,失效时随机sleep一个很短的时间,再次查询,如果失败在执行更新

​	针对多个热点key同时失效的问题,可以缓存时使用固定时间加上一个小的随机数,避免大量热点key同一时刻失效



#### 缓存雪崩

原因

​	缓存挂掉,或者大量缓存同时失效,这是所有的请求都会穿透到DB

办法

​	使用快速失败的熔断策略,减少DB瞬间压力

​	使用主从模式和集群模式来尽量保证缓存服务的高可用



#### redis中大key如何处理

- ***redis-cli --bigkeys 查找大key***
- 删除大key,需要分批次删除



#### redis中分布式锁的实现

- Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：
  - 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
  - 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。
- 基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。
  - 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
  - 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
  - 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；
- 加锁操作 SET lock_key unique_value NX PX 10000 
  - lock_key 就是 key 键；
  - unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
  - NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
  - PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。



基于 Redis 实现分布式锁的**优点**：

1. 性能高效（这是选择缓存实现分布式锁最核心的出发点）。
2. 实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。
3. 避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。

基于 Redis 实现分布式锁的**缺点**：

- 超时时间不好设置

  - 如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，注意 A 线程没执行完，后续线程 B 又意外的持有了锁，意味着可以操作共享资源，那么两个线程之间的共享资源就没办法进行保护了。

  - **那么如何合理设置超时时间呢？** 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。

- 

- **Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性**。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。



#### redis跳表

Redis 中的跳表（Skip List）是一种数据结构，用于实现有序集合。跳表通过在原有有序链表的基础上增加多层索引来提高查询效率，从而实现了快速查找、插入和删除操作。

跳表的特点包括：

1. **多层索引：** 跳表在原有的有序链表基础上增加了多层索引，每一层的节点是下一层节点的子集，最底层包含了所有元素，而每一层索引的元素数量逐渐减少，使得查询时可以跳过部分元素，从而提高了查询效率。

2. **查找效率：** 跳表通过多层索引的方式实现了二分查找的效果，使得查询的时间复杂度为 O(log n)，其中 n 为跳表中元素的数量。

3. **插入和删除操作：** 在跳表中进行插入和删除操作时，需要更新对应层级的索引，但由于每一层索引的元素数量较少，因此更新操作的开销较小，使得插入和删除的时间复杂度也为 O(log n)。

4. **平衡性：** 跳表的每一层索引都是有序的，因此跳表在插入和删除元素时需要保持索引的平衡，以维持查找效率。

5. **空间复杂度：** 跳表相对于平衡树等数据结构来说，空间复杂度较低，仅为 O(n)，其中 n 为跳表中元素的数量。

   

## Celery

#### 什么是 Celery

celery是一个开源的分布式任务队列系统,用于处理异步任务和分布式任务的调度.python编写,可以与多种后端消息代理(如RabbitMQ,redis,kafka等)集成,用于应用程序中执行异步任务.celery的主要用途是将耗时的,非阻塞的任务从主应用程序中分离出来,以提高应用程序的性能和相应速度.

以下是 Celery 的主要用途和功能：

1. **异步任务处理：** Celery 允许将耗时的任务（如发送电子邮件、生成报告、处理图像或视频等）异步执行，而不会阻塞主应用程序的运行。这可以提高应用程序的性能和用户体验，因为用户不需要等待长时间的任务完成。
2. **定时任务调度：** Celery 包含一个组件称为 Celery Beat，它可以用来调度定时任务，例如定时生成报告、定时备份数据或定时执行其他重复性任务。
3. **分布式任务：** Celery 支持在多台计算机上分布执行任务，这使得它适用于大规模、高并发的应用程序。任务队列可以在不同的工作者节点上并行执行任务。
4. **结果处理：** Celery 允许您获取异步任务的结果，以便进一步处理或通知用户。您可以将任务结果存储在各种后端中，例如数据库、缓存或消息队列。
5. **任务重试和错误处理：** Celery 提供了任务重试机制，如果任务执行失败，可以根据配置进行自动重试。您还可以定义错误处理方式，以便处理任务执行过程中出现的异常情况。
6. **可扩展性：** Celery 是一个高度可扩展的系统，可以根据需求添加新的工作者节点以处理更多任务负载，从而满足应用程序的需求。
7. **监控和管理：** Celery 提供了监控和管理工具，可以用于查看任务队列的状态、性能指标和日志信息，以及执行管理操作，如启动、停止和重启任务队列。



#### Celery 的架构是什么样的？

Celery 的架构是一个分布式任务队列系统，它包括任务生产者、任务队列和工作者（Workers）。以下是 Celery 的基本架构及其组件的描述：

1. **任务生产者（Task Producer）：**
   
   - 任务生产者是您的应用程序的一部分，负责创建和定义异步任务。
   - 生产者通常是应用程序的业务逻辑或视图函数，它们使用 Celery 提供的客户端库将任务提交到 Celery 任务队列。
   - 生产者将任务描述为函数调用，包括任务函数的名称、参数和关键字参数。
   - 生产者可以选择性地等待任务完成并获取任务的结果，或者只是提交任务并立即继续执行。

2. **任务队列（Task Queue）：**
   - 任务队列是 Celery 的核心组件，它接收和存储从任务生产者提交的任务。
   - 任务队列是一个分布式消息队列，负责维护待执行的任务列表。
   - 任务队列将任务分配给可用的工作者节点以执行。任务队列可以与不同的消息代理后端（如 RabbitMQ、Redis 等）集成，用于存储任务消息。
   - 任务队列还负责任务的调度和分发，以确保任务在工作者节点上按照一定的顺序和优先级执行。
   
3. **工作者（Workers）：**

   - 工作者是 Celery 集群中的任务执行者，它们负责从任务队列中获取任务并执行它们。
   - 工作者节点是分布式的，可以运行在多个计算机上，以处理任务队列中的任务。
   - 每个工作者节点都有一个或多个工作者进程，它们同时执行异步任务。
   - 工作者节点可以动态扩展，根据需要添加更多的工作者以处理高负载。
   - 工作者节点执行任务时，会将执行结果返回给任务队列，以便生产者或其他组件获取结果。

总体而言，Celery 的架构是一个生产者-任务队列-工作者的分布式系统，允许将异步任务提交到队列中，然后由工作者节点分布式执行。这种架构允许应用程序处理异步任务，提高了性能和可伸缩性，同时保持任务的可靠性和可重复性。Celery 还支持定时任务和分布式任务的管理，使其适用于多种不同的应用场景。



#### **Celery 和其他任务队列的比较？**

Celery 与其他任务队列（如 RabbitMQ、Redis Queue、Apache Kafka 等）相比，具有不同的优势和特点。以下是 Celery 与一些常见任务队列的比较：

1. **RabbitMQ：**
   - RabbitMQ 是一个强大的消息代理，也可以用作任务队列的后端。
   - 优势：
     - RabbitMQ 提供了可靠的消息传递，保证消息不会丢失。
     - 具有灵活的消息路由和交换机模型，支持复杂的消息传递场景。
     - 可以与多种编程语言和框架集成。
   - 不同之处：
     - Celery 是建立在 RabbitMQ 之上的一个任务队列系统，提供了更高级的任务管理和调度功能，而不仅仅是消息传递。
     - Celery 具有更丰富的任务管理和监控工具，适用于异步任务处理和定时任务。

2. **Redis Queue (RQ)：**
   - RQ 是一个基于 Redis 的任务队列库，用于处理异步任务。
   - 优势：
     - 简单易用，轻量级，快速启动。
     - 与 Redis 数据存储紧密集成，适合小型和简单的任务队列需求。
   - 不同之处：
     - Celery 提供了更多的高级特性，如定时任务、任务状态监控、任务优先级和任务重试机制。
     - Celery 具有更广泛的后端消息代理支持，适用于复杂的任务分发和管理。

3. **Apache Kafka：**
   - Apache Kafka 是一个分布式消息流平台，通常用于实时数据处理。
   - 优势：
     - 适用于大规模、高吞吐量的消息处理和日志流。
     - 具有持久性和高可用性，可用于数据管道和事件处理。
   - 不同之处：
     - Kafka 通常用于数据流处理，而不是任务队列。它更适合处理事件流和日志，而不是异步任务执行。
     - Celery 更专注于任务队列和异步任务处理，提供了更多相关特性。

总的来说，Celery 是一个强大且功能丰富的任务队列系统，适用于处理异步任务、定时任务和分布式任务。它在任务管理、监控和调度方面提供了许多高级功能。然而，选择任务队列取决于项目的需求和规模，以及您是否需要更复杂的任务处理和管理功能。其他任务队列，如 RabbitMQ、Redis Queue 和 Apache Kafka，也是在不同场景下有用的工具，可以根据具体需求进行选择。



#### **如何创建和调用 Celery 任务？**

要创建和调用 Celery 任务，需要遵循以下步骤：

1. **定义 Celery 任务函数：** 首先，您需要定义一个 Python 函数，这个函数将成为 Celery 任务。这个函数应该接受任意数量的参数，并返回任务的结果。例如：

   ```python
   from celery import Celery

   # 创建 Celery 应用
   celery = Celery('myapp')

   # 定义 Celery 任务
   @celery.task
   def add(x, y):
       return x + y
   ```

2. **提交任务到 Celery 队列：** 现在您可以在应用程序的其他部分调用 Celery 任务函数，并将任务提交到 Celery 队列中。例如：

   ```python
   # 导入任务函数
   from myapp import add

   # 提交任务到 Celery 队列
   result = add.delay(10, 20)
   ```

3. **获取任务结果（可选）：** 您可以选择等待任务完成并获取其结果，或者在后台处理任务而不等待。如果需要获取结果，可以使用 `result.get()` 方法：

   ```python
   # 获取任务结果
   result = add.delay(10, 20)
   result_value = result.get()
   print(result_value)  # 输出结果：30
   ```

4. **处理任务状态和错误（可选）：** 您可以监控任务的状态并处理任务可能出现的错误。Celery 提供了各种方式来查询任务的状态、获取结果或处理任务失败的情况。

这是一个完整的示例，演示了如何创建、提交和获取 Celery 任务的结果：

```python
# 在 myapp.py 中定义 Celery 任务
from celery import Celery

# 创建 Celery 应用
celery = Celery('myapp')

# 定义 Celery 任务
@celery.task
def add(x, y):
    return x + y
```

```python
# 在应用程序中提交 Celery 任务
from myapp import add

# 提交任务到 Celery 队列
result = add.delay(10, 20)

# 获取任务结果
result_value = result.get()
print(result_value)  # 输出结果：30
```

这样，您就可以成功创建和调用 Celery 任务。确保在应用程序中正确配置 Celery，并在需要时将任务提交到队列中。您可以使用 Celery 的其他功能来监控任务状态、处理任务错误和定时执行任务，以满足应用程序的需求。



#### Celery 的定时任务是如何工作的？

Celery 的定时任务是通过 Celery Beat 组件来管理和调度的。Celery Beat 是 Celery 生态系统的一个组件，它负责调度定时任务的执行。以下是 Celery Beat 是如何工作的：

1. **配置定时任务：** 首先，您需要在 Celery 配置中定义定时任务。这通常涉及创建一个 Python 模块，其中包含定时任务的配置。每个定时任务都由一个包含任务名称、任务函数、调度频率和其他相关信息的配置项组成。

   ```python
   # 定义定时任务
   from celery import Celery
   from celery.schedules import crontab

   celery = Celery('myapp')

   celery.conf.beat_schedule = {
       'my-task': {
           'task': 'myapp.my_task_function',
           'schedule': crontab(minute=0, hour=2),  # 每天凌晨2点执行
       },
   }
   ```

2. **启动 Celery Beat：** Celery Beat 是一个独立的进程，它在后台运行，并根据配置的时间表调度任务。您需要启动 Celery Beat 进程以开始定时任务的调度。

   ```bash
   celery -A myapp beat
   ```

3. **定时任务执行：** 一旦 Celery Beat 启动并根据时间表计划了任务，它将定时触发任务的执行。任务函数将被异步提交到 Celery 队列，然后由 Celery 工作者节点执行。

4. **监控和管理：** 您可以使用 Celery Beat 提供的管理工具来监控定时任务的执行情况。这包括查看任务的状态、执行时间、结果和错误等信息。

5. **错误处理：** 如果定时任务的执行失败，Celery Beat 通常会记录错误并根据您的配置采取相应的措施，例如重试任务或发送通知。

6. **修改任务时间表：** 如果需要更改定时任务的时间表，只需修改 Celery 配置中的时间表信息，并重启 Celery Beat 进程即可。Celery Beat 会自动根据新的时间表计划任务。

Celery Beat 的主要作用是定时任务的管理和调度，它允许您轻松地安排和执行定时任务，无需编写自定义定时任务管理代码。这对于需要定期执行任务的应用程序非常有用，例如生成报告、数据备份、清理任务等。通过配置和使用 Celery Beat，您可以确保定时任务按计划执行，提高了应用程序的自动化和可靠性。



#### 如何确保任务的顺序执行？

在 Celery 中，默认情况下，任务是并行执行的，而不会按照提交的顺序执行。但是，如果需要确保任务按照特定的顺序执行，可以采取以下一些方法：

1. **使用 Chord（和弦）：** Chord 是 Celery 提供的一种机制，用于在一组任务都完成时执行一个回调任务。您可以使用 Chord 来确保任务按照顺序执行，即在前一个任务完成后触发下一个任务。

   ```python
   from celery import chord

   # 定义任务函数
   @celery.task
   def task1():
       return 1

   @celery.task
   def task2(result_from_task1):
       return result_from_task1 + 2

   @celery.task
   def final_task(results):
       total = sum(results)
       print("Final Result:", total)

   # 使用 Chord 确保任务按顺序执行
   chord(task1.s() | task2.s() | final_task.s())()
   ```

   在上面的示例中，`task1` 和 `task2` 将按顺序执行，然后在两个任务都完成后，`final_task` 会执行。

2. **使用任务依赖关系：** Celery 允许您为任务定义依赖关系，以确保任务在特定顺序下执行。您可以使用 `task.set` 方法来设置任务的依赖关系。

   ```python
   from celery import chain

   # 定义任务函数
   @celery.task
   def task1():
       return 1

   @celery.task
   def task2(result_from_task1):
       return result_from_task1 + 2

   @celery.task
   def final_task(result_from_task2):
       print("Final Result:", result_from_task2)

   # 设置任务依赖关系以确保按顺序执行
   task_chain = chain(task1.s() | task2.s() | final_task.s())
   task_chain()
   ```

   在上面的示例中，任务链 `task1 -> task2 -> final_task` 会按照指定的顺序执行。

3. **使用同步任务：** 如果您希望任务完全按照顺序执行而不是异步执行，可以使用同步任务。这意味着在一个任务完成之前，下一个任务不会开始执行。这可以通过直接调用任务函数来实现。

   ```python
   result1 = task1.apply_async()
   result2 = task2.apply_async()
   
   # 等待任务1完成
   result1.get()
   
   # 等待任务2完成
   result2.get()
   ```

请注意，使用 Chord 或任务依赖关系通常更灵活，因为它们允许您在保持异步执行的同时确保任务的顺序。根据您的具体需求，可以选择其中一种方法来管理任务的执行顺序。



#### 什么是Celery的结果后端

Celery 的结果后端（Result Backend）是一种机制，用于存储和获取异步任务的执行结果。它允许您在任务执行完成后检索任务的结果，以便进一步处理或展示给用户。结果后端在 Celery 中扮演了重要的角色，特别是在需要跟踪任务状态和获取任务结果时非常有用。

以下是结果后端的一些关键特性和用途：

1. **存储任务结果：** 当您提交一个异步任务时，Celery 将任务的执行结果存储在结果后端中。这可以是数据库、消息代理（如 RabbitMQ 或 Redis）或其他可扩展的存储。

2. **结果的持久性：** 结果后端通常会将任务结果持久化存储，以确保即使在 Celery 服务重启后，您仍然可以获取到任务的结果。

3. **获取任务结果：** 通过异步任务的 `AsyncResult` 对象，您可以随时查询任务的状态并使用 `get` 方法来获取任务的结果。这是在任务完成后检索结果的常见方式。

4. **错误处理：** 如果任务执行失败，结果后端通常会存储相关的错误信息，以便您能够识别和处理问题。

5. **监控和报告：** 结果后端还允许您监控任务的执行情况，并生成报告或记录任务的执行历史。

Celery 支持多种结果后端，包括以下几种常见的：

- **数据库后端：** 将任务结果存储在关系数据库中，如 PostgreSQL、MySQL 或 SQLite。这是一种可靠的持久性存储解决方案。

- **消息代理后端：** 使用消息代理（如 RabbitMQ、Redis）作为结果后端，将任务结果作为消息发布到代理中。这是一种高效的方式，适用于短期结果存储。

- **自定义后端：** 您还可以编写自定义结果后端，以满足特定需求或与其他系统集成。

在配置 Celery 应用程序时，您需要指定所使用的结果后端。例如，在配置文件中设置 `result_backend` 参数来选择结果后端：

```python
# 使用 Redis 作为结果后端
result_backend = 'redis://localhost:6379/0'
```

通过配置正确的结果后端，您可以确保 Celery 在异步任务执行后，能够存储和检索任务的结果，以便后续处理和分析。



#### Celery的性能优化策略是什么?

优化 Celery 的性能是确保它能够有效处理大量任务和高并发的关键。以下是一些优化策略和最佳实践，以提高 Celery 的性能：

1. **并发性设置：** 配置 Celery 工作者的并发性设置以充分利用系统资源。您可以根据系统的 CPU 核数和可用内存来设置工作者的数量。确保不要设置过多的工作者，以免资源争夺和性能下降。

   ```python
   # 设置工作者的并发性
   worker_concurrency = 4  # 根据需要调整
   ```

2. **任务序列化：** 使用轻量级的任务序列化格式，例如 JSON，以降低任务序列化和反序列化的开销。

   ```python
   # 使用 JSON 序列化任务
   task_serializer = 'json'
   result_serializer = 'json'
   ```

3. **消息代理优化：** 如果使用消息代理作为 Celery 的消息传输机制，确保消息代理配置优化，以提高消息传递的性能和稳定性。对于 RabbitMQ，您可以配置持久队列和消息以确保数据的可靠性。

4. **结果后端优化：** 根据应用程序需求选择适当的结果后端。数据库后端适合长期存储，消息代理后端适用于短期存储。在高负载情况下，选择高性能的结果后端，如 Redis。

5. **任务批量处理：** 将多个任务合并为批量任务，以减少任务提交和结果处理的开销。这对于大量小型任务的情况特别有用。

6. **任务超时设置：** 配置任务的超时时间，以防止长时间运行的任务影响系统性能。使用 `soft_timeout` 和 `hard_timeout` 配置任务的超时。

   ```python
   # 设置任务的软超时和硬超时
   task_soft_time_limit = 60  # 软超时时间（秒）
   task_time_limit = 120     # 硬超时时间（秒）
   ```

7. **监控和日志：** 使用监控工具来实时监视 Celery 的性能和运行状态。合适的日志设置有助于诊断和解决性能问题。

8. **扩展工作者节点：** 在高负载情况下，考虑在多台服务器上运行 Celery 工作者，以平衡负载和提高处理能力。

9. **使用缓存：** 对于频繁读取的数据，考虑使用缓存来减轻数据库负载，提高数据访问速度。

10. **定时任务调优：** 如果使用 Celery Beat 进行定时任务调度，确保合理设置任务的时间表，避免在高峰期触发大量任务。

11. **错误处理策略：** 配置适当的任务重试和错误处理策略，以确保任务失败时能够恢复或采取适当的措施。

12. **升级 Celery 版本：** 定期升级到最新的 Celery 版本，以获取性能改进和 bug 修复。

请注意，性能优化是一个动态过程，需要不断监控和调整，以满足应用程序的需求。根据具体情况，您可能需要采取以上策略的组合来最大程度地提高 Celery 的性能。



## RabbitMQ

#### RabbitMQ的作用

- 解耦
  - 一个大的系统会分为部分子系统,当主系统发送消息到子系统时,需要和各个子系统进行对接,如果需要进行扩展或者业务的调整,就需要对主系统的代码接口进行维护,十分的麻烦,这个时候使用MQ就可以有效的解决这个问题,主系统之需要把消息发送到MQ,子系统自行消费,主系统就无需关注子系统是谁,怎么消费消息,怎么获取消息.只要配置好规则的子系统都能获取到消息
- 异步
  - 主系统接受一个请求后,需要在各个子系统落库,如果等到各个子系统落库完成,整个的请求时间就会非常长,这时候使用MQ把消息发送到队列,主系统就可以返回请求,用户的体验感更好
- 削峰
  - 可以极大的减小高峰时服务器的压力

#### RabbitMQ的基本概念

- Broker： 简单来说就是消息队列服务器实体

- Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列

- Queue： 消息队列载体，每个消息都会被投入到一个或多个队列

- Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来

- Routing Key： 路由关键字，exchange根据这个关键字进行消息投递

- VHost： vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。

- Producer： 消息生产者，就是投递消息的程序

- Consumer： 消息消费者，就是接受消息的程序

- Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务



#### MQ的缺点

- 系统可用性降低
  - 如果消息队列挂了,整个服务会受一定的影响,增加的整体系统的维护难度
- 系统复杂度增加
  - 加入了队列,增加了功能,整体复杂性加大
- 一致性问题
  - 主系统发送完消息后直接返回了,但子系统可能个别没有正常的消费消息,导致数据不一致的问题



#### MQ如何保证消息的顺序性

- 拆分多个queue(消息队列),每个queue一个consumer
- 一个queue一个consumer,consumer内部使用内存队列做排队,然后分发给不同worker进行处理



#### MQ如何保证消息的可靠性

- 生产者丢失消息
  - RabbitMQ提供了transaction机制, transaction机制是发送消息前,开启事务(channel.txSelect()),如果发送过程中发生什么异常,事务就会回滚(channel.txRollback()),如果发送成功则提交事务(channel.txCommit()),缺点是吞吐量下降
  - RabbitMQ提供了confirm模式,一旦channel进入confirm模式,所有该信道上发布的消息都会被指定一个唯一ID(从1开始),一旦消息到达所匹配的队列之后,RabbitMQ就会发送一个ACK给到生产者(包含信息的唯一ID),这样生产者就知道消息到达队列了,如果RabbitMQ没有处理该消息,则会发送一个Nack消息给到你,你可以进行重试操作.
- 消息队列丢数据
  - 消息持久化,开启RabbitMQ的持久话的配置,将queue的持久化标识durable设置为true,则代表是一个持久的队列
- 消费者丢失消息
  - 消费者丢失数据一般都是因为开启了自动确认消息模式,改为手动确认即可



#### MQ怎样防止重复消费

- 保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性





## **Gunicorn**

1. **什么是 Gunicorn？**

   Gunicorn 是一个 Python WSGI HTTP 服务器，用于部署 Python Web 应用程序。

2. **Gunicorn 的工作原理是什么？**

   Gunicorn 通过监听指定的主机和端口，接收客户端请求，并将其转发给 Web 应用程序处理。它利用多个 worker 进程处理请求，每个 worker 都可以同时处理一个或多个客户端连接。Gunicorn 使用预先分配的 worker 进程池来提高并发性能，并通过主进程管理 worker 的生命周期。

3. **如何在命令行中启动 Gunicorn？**

   可以使用以下命令启动 Gunicorn：

   ```python
   phpCopy code
   gunicorn <app_module>:<app_instance> -w <num_workers> -b <bind_address>
   ```

   其中 `<app_module>:<app_instance>` 是应用程序的入口点，`<num_workers>` 是工作进程数量，`<bind_address>` 是绑定的主机和端口。

4. **Gunicorn 的配置文件是什么？**

   Gunicorn 的配置文件是一个 Python 模块，通常命名为 `gunicorn.conf.py`，用于配置服务器的行为和性能参数。可以在配置文件中指定 worker 数量、日志设置、访问日志格式等。

5. **什么是 Gunicorn 的 worker？**

   Gunicorn 的 worker 是服务器进程池中的工作进程，负责处理客户端请求并执行 Web 应用程序的代码。每个 worker 进程都独立于其他进程，并处理来自客户端的请求。

6. **如何监控和管理 Gunicorn 服务器？**

   可以使用 Gunicorn 提供的命令行工具或 API 来监控服务器的运行状态、重启服务器、动态调整 worker 数量等操作。例如，可以使用 `gunicornctl` 命令来启动、停止或重启服务器。

7. **Gunicorn 的异步模式是什么？**

   Gunicorn 支持异步模式，允许它与异步框架（如 asyncio、Tornado 等）和异步代码执行兼容。通过配置 Gunicorn 使用异步 worker 类型，可以实现对异步代码的支持和优化。

8. **Gunicorn 与其他 WSGI 服务器有什么区别？**

   Gunicorn 具有简单易用的特点，易于部署和配置。相比其他 WSGI 服务器，如 uWSGI、Apache、Nginx，Gunicorn 在处理 Python Web 应用程序时通常更加高效和稳定。其内置的 worker 进程管理机制和自动重启功能使得 Gunicorn 成为许多 Python 开发人员首选的 Web 服务器之一。

   

## 网络

### TCP/IP 网络模型有哪几层

- 应用层
  - 就是网络的最上层,应用层只需要给用户提供应用功能,比如 HTTP、FTP、Telnet、DNS、SMTP等

- 传输层
  - 应用层会把数据包传给传输层,传输层为应用层提供网络支持
  - 传输层有两个传输协议,分别是TCP,UDP
  - TCP全称是传输控制协议,TCP比UDP多了很多的特性,比如流量控制,超时重传,拥塞控制等,这些都是为了保证数据包可靠的传输给对方,TCP传输数据的时候由于数据的大小,往往需要分段.应用层接收数据的时候,可能会有很多的应用,就需要用端口区分
  - UDP只是简单的负责发送数据包,不保证数据包是否能否抵达对方,实时性更好,效率更高
- 网络层
  - 网络层需要将一个数据从一个设备传输到另一个设备,需要通过ip能识别设备
- 网络接口层
  - 生成了 IP 头部之后，接下来要交给**网络接口层**（*Link Layer*）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。

### 输入网址到显示内容发生了什么

- 域名解析(DNS解析)
- 建立TCP连接
- 发送HTTP请求
- 服务器处理请求
- 服务器响应HTTP请求
- 传输HTML内容
- 页面渲染

### HTTP

- http的基本概念

  - http就是超文本传输协议

  - http常见的状态码

    - 1xx: 提示信息,协议处理的一种中间状态
    - 2xx: 服务器成功处理了请求
    - 3xx: 重定向
      - 301: 永久重定向
      - 302: 临时重定向
      - 304: 不具有跳转含义,表示资源未修改

    - 4xx: 请求错误
      - 400: 请求错误
      - 403: 请求被拒绝
      - 404: 没有此资源
    - 5xx: 服务器内部错误
      - 500: 服务器内部错误
      - 501: 表示客户端的请求还未支持
      - 502: 网关错误
      - 503: 服务器忙

- http和https的区别

  - http:
    - 超文本传输协议,明文传输,存在安全风险
    - 80端口
  - https:
    - 在TCP和http网络层之间加入了SSL/TLS 安全协议，使得报文能够加密传输
    - 443端口
    - HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

  - https解决了http哪些问题:

    - http存在窃听风险,篡改风险,冒充风险
    - HTTPS 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了上述的风险
      - 信息加密
      - 校验机制
      - 身份证书

    - HTTPS 是如何解决上面的三个风险的？
      - **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
      - **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险
      - 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

  - https的应用数据是如何保持完整性的

    - TLS 在实现上分为**握手协议**和**记录协议**两层：

      - TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；

      - TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；

## 项目

#### Redis在项目过程中做了哪些事?

1. **缓存存储**：Redis 可以作为缓存存储，用于存储频繁访问且相对稳定的数据，以减轻 MySQL 数据库的压力。对于经常被查询的数据，如用户信息、权限信息等，可以存储在 Redis 缓存中，减少数据库查询的次数，提高系统性能和响应速度。
2. **会话管理**：Redis 可以用作会话存储，用于存储用户的会话信息。通过存储会话信息，可以实现用户登录状态的持久化，并且支持会话的跨平台和跨设备访问。
3. **分布式锁**：在多个模块之间共享资源时，可能会出现竞争条件。Redis 提供了分布式锁机制，可以帮助我们实现对共享资源的安全访问，避免出现数据竞争和并发问题。
4. **消息队列**：Redis 提供了消息队列的支持，可以用于模块之间的异步通信和解耦。例如，在飞书消息接入模块中，可以将接收到的消息放入 Redis 队列中，然后由 Celery Worker 进程异步处理这些消息，从而实现解耦和异步处理。
5. **计数器和统计数据存储**：Redis 提供了原子计数器和高效的数据结构，可以用于存储和统计系统的运行状态、访问量、性能指标等信息，以便后续的监控和分析。

#### 项目遇到过什么性能瓶颈?

#### 组内分工

#### 解耦体现在什么方面

#### 项目做了什么模块

#### 项目介绍,用了什么技术栈



## 面经

#### 单元测试覆盖率

#### 百万级别的数据如何高效存储

1. **数据模型设计**：合理设计数据模型是高效存储的基础。根据业务需求和数据特点，选择合适的数据结构和字段类型，并进行范式化或反范式化处理，以提高数据的存储效率和查询性能。

2. **数据清洗和预处理**：在数据存入之前，进行数据清洗和预处理是非常重要的。包括数据去重、数据格式化、数据规范化等操作，可以减小存储空间，提高数据质量，同时降低后续数据处理的复杂度。

3. **数据压缩**：对于大量文本、图片等数据，可以考虑使用数据压缩技术在存入之前进行压缩，减小数据的存储空间。常见的压缩算法包括gzip、bzip2等，可以根据数据特点选择合适的压缩算法。

4. **批量写入和并行处理**：在数据存入过程中，采用批量写入和并行处理的方式可以提高数据存入的效率。将数据分批次写入数据库或存储系统，并利用多线程、多进程等技术实现并行处理，可以减少存入时间并提高系统的吞吐量。

5. **使用高效的存储引擎**：选择合适的存储引擎也是非常重要的。针对不同的数据特点和访问模式，选择适合的存储引擎可以提高数据的读写性能和存储效率。常见的存储引擎包括关系型数据库的InnoDB、文档型数据库的MongoDB等。

6. **数据分区和分片**：根据数据的特点和访问模式，可以考虑将数据进行分区和分片存储，以提高数据的读写性能和存储效率。例如，按照时间、地域等维度进行数据分区，或者按照哈希值进行数据分片，可以将数据均匀分布在多个存储节点上，从而提高系统的扩展性和容错性。

   

#### celery 单节点怎样保证定时任务创建broker的可靠性

- 使用持久化任务调度器: celery提供了脚celery beat的任务调度器,它负责定时任务的调度和管理,在单节点的情况下可以配置持久化的后端存储(如数据库),这样即使celery beat进程意外终止或者重启,定时任务的配置信息依然可以被保留下来,确保不会丢失
- 使用监控和报警机制: 设置监控和报警机制来监控celery beat的运行状态,可以使用监控工具来监控,设置告警机制,出现异常情况时及时通知管理员
- 合理的异常处理策略: 可以配置在celery beat在启动时自动恢复上次的中断状态,或者设置在celery beat在异常终止后自动重启
- 定期备份配置信息: 可以使用定时任务定期备份配置信息到安全的位置,以便在需要的时候进行恢复

#### mysql innodb的数据结构

https://www.51cto.com/article/673996.html



#### python启动程序后的资源分配情况

Python运行代码后的资源分配取决于代码的性质和代码中所执行的操作。以下是一些常见的资源分配情况：

1. **内存分配：** 当您运行Python代码时，Python解释器会分配内存来存储程序的数据结构、变量和对象。内存分配是动态的，根据需要进行。这包括分配内存以存储变量、列表、字典、对象等。

2. **CPU 资源：** Python代码在CPU上执行计算和操作。CPU资源用于执行代码中的各种操作，包括数学运算、逻辑判断、函数调用等。

3. **文件系统资源：** 如果您的代码涉及文件的读取、写入或操作，Python会分配文件系统资源，包括文件句柄和缓冲区。

4. **网络资源：** 如果您的代码与网络通信，例如通过HTTP请求或Socket连接，Python会分配网络资源，包括套接字和网络带宽。

5. **数据库连接资源：** 如果您的代码连接到数据库，Python会分配数据库连接资源，以便与数据库服务器通信。

6. **进程和线程资源：** 如果您的代码涉及多线程或多进程操作，Python会分配相关资源，包括线程和进程资源。

7. **GPU 资源（如果适用）：** 对于某些应用程序，例如深度学习和科学计算，Python代码可以分配GPU资源以加速计算。

8. **其他外部设备资源：** 如果您的代码需要与外部设备（例如摄像头、传感器、打印机等）通信，Python可能会分配相关资源。

9. **系统调用资源：** 代码中的系统调用（例如调用操作系统API）可能分配系统资源，例如打开文件、创建进程等。

10. **内部资源管理：** Python还管理内部资源，如线程池、内存池和内部数据结构，以支持并发执行和内存分配。

这些资源的分配和管理是由Python解释器和操作系统共同完成的。Python解释器会跟踪和管理这些资源，确保它们在程序执行期间得到适当的分配和释放。合理管理这些资源对于确保程序的性能、稳定性和可靠性至关重要。



#### python各个web框架的区别

1. **Django：**
   - **全功能框架：** Django 是一个全功能的 Web 框架，提供了众多内置功能，包括认证、ORM、模板引擎、管理后台等。
   - **高度集成：** Django 的组件高度集成，使得开发速度快，但可能缺少一些灵活性。
   - **适用场景：** 适用于快速构建大型、复杂的 Web 应用程序，如社交媒体网站、电子商务平台等。
2. **Flask：**
   - **微框架：** Flask 是一个微框架，提供了最基本的工具和库，但允许开发者选择并集成其他组件。
   - **轻量级：** Flask 的设计非常轻量级，它更像是一个工具箱，可以根据需要选择添加功能。
   - **适用场景：** 适用于快速原型开发、小型项目、API 服务和微服务
3. **FastAPI：**
   - **现代 Web 框架：** FastAPI 是一个现代的 Web 框架，用于构建高性能的 API 服务。它使用 Python 3.6+ 的类型注解和自动生成文档。
   - **快速开发：** FastAPI 支持快速开发，并提供强大的请求和响应验证。
   - **适用场景：** 适用于构建 API 服务，特别是需要自动生成文档和输入验证的情况。



#### logging模块是线程安全的吗

在 Python 中，logging 模块是线程安全的。这意味着你可以在多个线程中同时使用 logging 模块，而不必担心由于多线程并发访问而导致的日志记录问题。

logging 模块在设计时考虑到了多线程环境下的使用，因此在内部实现中使用了线程锁（thread lock）来保护对共享资源的访问。具体来说，当多个线程同时尝试记录日志时，logging 模块会自动获取线程锁，以确保一次只有一个线程可以访问日志记录器，并且在记录完日志后释放锁，以允许其他线程进行访问。

因此，使用 logging 模块记录日志时，你无需担心线程安全性问题，可以放心地在多线程环境中使用

#### python的int为什么能操作64位

在 Python 中，整数的长度是动态的，并且可以表示任意大小的整数。Python 中的 int 类型可以处理 64 位以上的整数，因为 Python 的整数不受特定位数的限制，而是根据系统的内存大小来动态调整。在 64 位系统上，Python 的整数可以占用 64 位，但它们不仅限于 64 位。因此，Python 中的整数可以表示为任意长度，而不仅仅是 64 位。

#### ELK是什么

ELK是一套针对日志数据做解决方案的框架，分别代表了三款产品： - E: ElasticSearch（ES），负责日志的存储和检索； - L：Logstash，负责日志的收集，过滤和格式化； - K：Kibana，负责日志的展示统计和数据可视化

- Elasticsearch是一个分布式的免费开源搜索和分析引擎，适用于包括文本、数字、地理空间、结构化 和非结构化数据等在内的所有类型的数据。Elasticsearch在ApacheLucene的基础上开发而成，由 ElasticsearchN.V.（即现在的Elastic）于2010年首次发布。Elasticsearch以其简单的REST风格 API、分布式特性、速度和可扩展性而闻名，是ElasticStack的核心组件；ElasticStack是一套适用
  于数据采集、扩充、存储、分析和可视化的免费开源工具。人们通常将ElasticStack称为ELKStack （代指Elasticsearch、Logstash和Kibana），目前ElasticStack包括一系列丰富的轻量型数据采
  集代理，这些代理统称为Beats，可用来向Elasticsearch发送数据。

#### RESTFUL api了解什么？基于restful api的风格如何设计用户的增删改查的url？怎么写接口文档?patch 和 put有什么区别？

- RESTFUL api:
  - 是一种设计风格,通过URL来表示资源,HTTP方法来表示对资源的操作,以及使用状态吗和响应体来表示请求结果
- restful api对于用户的增删改查的操作:
  - 获取用户信息：GET /users/{user_id}
  - 创建用户：POST /users
  - 更新用户信息：PUT /users/{user_id} 或 PATCH /users/{user_id}
  - 删除用户：DELETE /users/{user_id}
- 接口文档:
  - 包括接口的url,请求方式,请求参数,请求返回,请求事例,响应状态码和其中的含义
- patch 和 put有什么区别？
  - put是对数据进行全量更新是幂等的
  - patch是对数据进行部分更新,是非幂等的

#### url里拼接和body里面传递的参数，分别如何获取

- url: request.args返回字典,所有的url请求参数
- body: request.json用于获取json格式的参数



#### 有没有做序列化？你是怎么封装的？

- 统一的拦截器,对数据进行处理,统一返回,包括状态吗,成功与否,数据结果



#### mysql什么情况下会导致索引失效

- **对索引使用左或者左右模糊匹配**,比如 like %xxx 或者like%xxx% ,会造成全表搜索
- **对索引进行函数计算**,因为索引保存的是索引字段的原始值,而不是函数计算后的值
- **对索引进行表达式计算**,同上
- **对索引进行隐性类型转换**, **MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较**。 字段是字符串,查询是数字,相当于对字段进行了函数计算.  字段是数字,,查询是字符串,会把查询的输入转成数字,并没有对字段进行函数操作,所以索引生效
- **联合索引非最左匹配**
  - where a=1；生效
  - where a=1 and b=2 and c=3；生效
  - where a=1 and b=2；生效
  - 以上因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要
  - where b=2；
  - where c=3；
  - where b=2 and c=3
  - 如果查询条件是以上这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效
  - where a = 1 and c = 3 
  - MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。
  - MySQL 5.6 之后，有一个**索引下推功能**，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。

- where字句中的or
  - 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



#### RBAC模型是什么

- RBAC(Role-Based Access Control)模型是基于角色的访问控制模型,是一张常见的访问控制策略,用于管理系统中的权限和资源访问,权限被分配给角色,一个用户可以有一个或多个角色,用户通过角色来获取权限,从而访问系统中的资源

- 简化权限管理

- 灵活性和可扩展性

- 安全性

  

- 用户表：用户ID、用户名、密码等。

- 角色表：角色ID、角色名称等。

- 权限表：权限ID、权限名称、权限描述等。

- 用户角色关联表：关联ID、用户ID、角色ID。

- 角色权限关联表：关联ID、角色ID、权限ID。



#### 高并发系统的设计

- 系统拆封
  - 将一个系统拆封成多个子系统,每个子系统连接一个数据库
- 缓存
  - 大部分的场景都是读多写少,读多的场景使用缓存,单机redis就可以扛住很高的并发
- MQ
  - 高并发写的时候,大量的请求写入MQ,慢慢排队由后边的系统慢慢消费,使用MQ来异步写
- 分库分表
  - 单表数据量过多,哪怕索引设计的优秀,性能也会降低,一个库拆分成多个库,一个表拆分成多个表,数据量减少,提高sql的性能
- 读写分离
  - 读多写少,主库写,从库读
- ES
  - 一些简答的查询,统计类工作,全文搜索类工作,可以考虑用ES完成

